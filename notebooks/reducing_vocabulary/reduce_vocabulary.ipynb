{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', '.', ';']\n"
     ]
    }
   ],
   "source": [
    "from m2_cw import load_qwen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from bidict import bidict\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "\n",
    "model, tokenizer = load_qwen(reduce_vocabulary=False)\n",
    "device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "valid_words = list(\"0123456789,.;\")\n",
    "print(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     token += \u001b[32m1\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Get qwens embedding vector for the word\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     embedding_vector = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqwen_token_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     embedding_vectors.append(embedding_vector)\n\u001b[32m     22\u001b[39m token_map = bidict({qwen: forecast \u001b[38;5;28;01mfor\u001b[39;00m qwen, forecast \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(qwen_tokens, new_tokens)})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/m2_venvs/m2_coursework/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/m2_venvs/m2_coursework/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/m2_venvs/m2_coursework/lib/python3.13/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/m2_venvs/m2_coursework/lib/python3.13/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index out of range in self"
     ]
    }
   ],
   "source": [
    "new_model = copy.deepcopy(model)\n",
    "# Work out qwens tokens for this vocabulary\n",
    "qwen_tokens = []\n",
    "new_tokens = []\n",
    "embedding_vectors = []\n",
    "\n",
    "token = 0\n",
    "for word in valid_words:\n",
    "    # Get qwen's token for the word\n",
    "    qwen_token_tensor = tokenizer(word, return_tensors=\"pt\", add_special_tokens=False).input_ids[0]\n",
    "    qwen_token = qwen_token_tensor.item()\n",
    "    qwen_tokens.append(qwen_token)\n",
    "\n",
    "    # define my token for the word\n",
    "    new_tokens.append(token)\n",
    "    token += 1\n",
    "\n",
    "    # Get qwens embedding vector for the word\n",
    "    embedding_vector = model.model.embed_tokens(qwen_token_tensor)\n",
    "    embedding_vectors.append(embedding_vector)\n",
    "\n",
    "token_map = bidict({qwen: forecast for qwen, forecast in zip(qwen_tokens, new_tokens)})\n",
    "\n",
    "\n",
    "# Make the embedding vectors into torch parameters\n",
    "embedding_vectors = torch.concat(embedding_vectors)\n",
    "embedding_vectors = nn.Parameter(embedding_vectors)\n",
    "\n",
    "\n",
    "# make new embedding that only has tokens from our allowed words list\n",
    "new_embedding = nn.Embedding(num_embeddings=len(new_tokens), embedding_dim=model.model.embed_tokens.embedding_dim)\n",
    "new_embedding.weight = embedding_vectors\n",
    "new_model.model.embed_tokens = new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting to forecast\n",
      "26\n",
      "converting to qwen\n",
      "12\n",
      "{'input_ids': tensor([[16, 13, 17, 18, 11, 23, 13, 16, 17, 26],\n",
      "        [24, 13, 23, 22, 11, 22, 13, 19, 18, 26]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[ 1, 11,  2,  3, 10,  8, 11,  1,  2, 12],\n",
      "        [ 9, 11,  8,  7, 10,  7, 11,  4,  3, 12]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[16, 13, 17, 18, 11, 23, 13, 16, 17, 26],\n",
      "        [24, 13, 23, 22, 11, 22, 13, 19, 18, 26]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "def convert_tokens_to(desired_type: str,\n",
    "                      tokens: BatchEncoding, \n",
    "                      map: bidict=token_map):\n",
    "\n",
    "    # Make lookup for the conversion\n",
    "    if desired_type == \"forecast\":\n",
    "        print(\"converting to forecast\")\n",
    "        max_key = max(token_map.keys())\n",
    "        print(max_key)\n",
    "        lookup = torch.full((max_key + 1,), -1)  # use -1 or some default for unmapped\n",
    "        for k, v in token_map.items():\n",
    "            lookup[k] = v\n",
    "\n",
    "    elif desired_type == \"qwen\":\n",
    "        print(\"converting to qwen\")\n",
    "        max_key = max(token_map.values())\n",
    "        print(max_key)\n",
    "        lookup = torch.full((max_key + 1,), -1)\n",
    "        for k, v in token_map.items():\n",
    "            lookup[v] = k\n",
    "\n",
    "    new_input_ids = lookup[tokens.input_ids]\n",
    "    new_tokens = copy.deepcopy(tokens)\n",
    "    new_tokens[\"input_ids\"] = new_input_ids\n",
    "    return new_tokens\n",
    "\n",
    "string = [\"1.23,8.12;\", \"9.87,7.43;\"]\n",
    "\n",
    "qwen_tokens = tokenizer(string, return_tensors=\"pt\", add_special_tokens=False)\n",
    "forecast_tokens = convert_tokens_to(\"forecast\", qwen_tokens)\n",
    "qwen_tokens_again = convert_tokens_to(\"qwen\", forecast_tokens)\n",
    "\n",
    "print(qwen_tokens)\n",
    "print(forecast_tokens)\n",
    "print(qwen_tokens_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=896, out_features=13, bias=True)\n"
     ]
    }
   ],
   "source": [
    "lm_head = model.lm_head\n",
    "new_weight = []\n",
    "new_bias = []\n",
    "for qwen, forecast in token_map.items():\n",
    "    weights = lm_head.weight[qwen, :].unsqueeze(0)\n",
    "    bias = lm_head.bias[qwen]\n",
    "    new_weight.append(weights)\n",
    "    new_bias.append(bias)\n",
    "\n",
    "\n",
    "new_weight = torch.concat(new_weight, dim=0)\n",
    "new_weight = nn.Parameter(new_weight)\n",
    "new_bias = torch.tensor(new_bias)\n",
    "new_bias = nn.Parameter(new_bias)\n",
    "new_lm_head = nn.Linear(in_features=lm_head.in_features, out_features=new_bias.shape[0], bias=True)\n",
    "new_lm_head.weight = new_weight\n",
    "new_lm_head.bias = new_bias\n",
    "\n",
    "print(new_lm_head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2 Coursework (Python)",
   "language": "python",
   "name": "m2_coursework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
